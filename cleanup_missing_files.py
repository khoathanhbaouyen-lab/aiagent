# cleanup_missing_files.py
# Script ƒë·ªÉ x√≥a metadata c·ªßa c√°c file kh√¥ng c√≤n t·ªìn t·∫°i tr√™n disk

import os
import sys
import re
from dotenv import load_dotenv
from langchain_chroma import Chroma
from langchain_openai import OpenAIEmbeddings

# Load environment variables
load_dotenv()

# C·∫•u h√¨nh
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
CHROMA_DIR = os.path.join(BASE_DIR, "user_data", "shared_vector_db")
PUBLIC_FILES_DIR = os.path.join(BASE_DIR, "public", "files")

def cleanup_missing_files():
    """X√≥a metadata c·ªßa file kh√¥ng t·ªìn t·∫°i"""
    
    print(f"üìÇ Connecting to ChromaDB at: {CHROMA_DIR}")
    
    # Initialize embeddings (needed for Chroma)
    embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
    
    # Initialize vectorstore
    vectorstore = Chroma(
        persist_directory=CHROMA_DIR,
        embedding_function=embeddings,
        collection_name="shared_memory"
    )
    
    collection = vectorstore._collection
    
    # L·∫•y t·∫•t c·∫£ documents
    all_data = collection.get(include=["metadatas"])
    
    ids_to_delete = []
    total_files = 0
    missing_files = 0
    
    print(f"ƒêang qu√©t {len(all_data['ids'])} documents...")
    
    for doc_id, metadata in zip(all_data['ids'], all_data['metadatas']):
        if not metadata:
            continue
            
        file_type = metadata.get("file_type")
        
        # Ch·ªâ ki·ªÉm tra file/image (kh√¥ng ph·∫£i text notes)
        if file_type in ["image", "file", "pdf", "excel", "word"]:
            total_files += 1
            
            # Parse file path t·ª´ original_content
            original_content = metadata.get("original_content", "")
            
            path_match = re.search(r"path=([^|]+)", original_content)
            
            if path_match:
                file_path = path_match.group(1).strip()
                
                # Ki·ªÉm tra file c√≥ t·ªìn t·∫°i kh√¥ng
                if not os.path.exists(file_path):
                    print(f"‚ùå Missing: {file_path}")
                    ids_to_delete.append(doc_id)
                    missing_files += 1
    
    print(f"\nüìä Th·ªëng k√™:")
    print(f"   - T·ªïng s·ªë file/·∫£nh: {total_files}")
    print(f"   - File kh√¥ng t·ªìn t·∫°i: {missing_files}")
    print(f"   - File c√≤n t·ªìn t·∫°i: {total_files - missing_files}")
    
    if ids_to_delete:
        print(f"\n‚ö†Ô∏è  S·∫Ω x√≥a {len(ids_to_delete)} metadata c·ªßa file kh√¥ng t·ªìn t·∫°i.")
        confirm = input("X√°c nh·∫≠n x√≥a? (y/n): ")
        
        if confirm.lower() == 'y':
            # X√≥a theo batch (ChromaDB gi·ªõi h·∫°n batch size)
            batch_size = 100
            for i in range(0, len(ids_to_delete), batch_size):
                batch = ids_to_delete[i:i+batch_size]
                collection.delete(ids=batch)
                print(f"   ƒê√£ x√≥a {len(batch)} metadata...")
            
            print(f"‚úÖ ƒê√£ x√≥a {len(ids_to_delete)} metadata!")
        else:
            print("‚ùå H·ªßy thao t√°c.")
    else:
        print("\n‚úÖ Kh√¥ng c√≥ file n√†o b·ªã missing. Database s·∫°ch!")

if __name__ == "__main__":
    cleanup_missing_files()
